{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EAzHL9kVf69G"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5AsfyCDJgmR0"
   },
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"vectorized.csv\")\n",
    "spam.drop([\"Unnamed: 0\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1TGJTcshOyi",
    "outputId": "ea542c3a-e407-4ce0-a3cd-a69ea8c05ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call': 342, 'free': 180, '2': 169, 'ur': 144, 'txt': 136}\n"
     ]
    }
   ],
   "source": [
    "# Get a list of stop words from https://gist.github.com/sebleier/554280\n",
    "with open('stopwords.txt') as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "\n",
    "def getTopSpam(df, commonWords, num):\n",
    "  '''\n",
    "  Returns the most common 'num' words in the spam messages.\n",
    "  '''\n",
    "  spam = {}\n",
    "  ham = []\n",
    "\n",
    "  # Gets count of all words in spam that are not in the list of common words\n",
    "  for idx in range(len(df.index)):\n",
    "    message = df.iat[idx, 1]\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "      if word not in commonWords and df.iat[idx, 0] == \"spam\":\n",
    "        if word not in spam:\n",
    "          spam[word] = 1\n",
    "        elif word in spam:\n",
    "          spam[word] = spam[word] + 1\n",
    "   \n",
    "  spam = sorted(spam.items(), key=lambda x:x[1], reverse=True)\n",
    "  return dict(spam[:num])\n",
    "\n",
    "result = getTopSpam(spam, lines, 5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zIlKBOC7lfl_"
   },
   "outputs": [],
   "source": [
    "def testTrainSplit(df):\n",
    "  length = len(spam.index)\n",
    "  split_limit = int(length * 0.7)\n",
    "  train = spam[0:split_limit]\n",
    "  test = spam[split_limit:length]\n",
    "  return train, test\n",
    "\n",
    "train, test = testTrainSplit(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "28wdz9zEgwQ4",
    "outputId": "16d8bd64-80f5-47c4-c75a-4b6fe48f8bc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>2</th>\n",
       "      <th>ur</th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call  free  2  ur  txt label\n",
       "0     0     0  0   1    0   ham\n",
       "1     0     0  0   0    0   ham\n",
       "2     0     1  1   0    1  spam\n",
       "3     0     0  0   0    0   ham\n",
       "4     0     0  0   0    0   ham"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeVectorTable(df):\n",
    "  '''\n",
    "  This function displays the message vectors like the stolen car data table seen\n",
    "  in our first lecture on Naive Bayes.\n",
    "  '''\n",
    "  feature_records = []\n",
    "  for idx in range(len(df)):\n",
    "    feature_vector = []\n",
    "    msg = df.iat[idx, 1]\n",
    "    label = df.iat[idx, 0]\n",
    "    for word in result.keys():\n",
    "      feature_vector.append(1 if word in msg else 0)\n",
    "    feature_vector.append(label)\n",
    "    feature_records.append(feature_vector)\n",
    "  feature_df = pd.DataFrame(feature_records)\n",
    "  columns = list(result.keys())\n",
    "  columns.append('label')\n",
    "  feature_df.columns = columns\n",
    "  return feature_df\n",
    "  \n",
    "feature_df = makeVectorTable(train)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-0Si4l8Pinbb",
    "outputId": "309bd615-cb18-4eae-ea5f-a6a62d3ec7c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13307692307692306 0.8669230769230769\n"
     ]
    }
   ],
   "source": [
    "def getProbHamSpam(df, feature_df):\n",
    "  '''\n",
    "  Gets the overall probability of ham and spam labels in dataframe\n",
    "  '''\n",
    "  p_spam = feature_df[feature_df.label == 'spam'].label.count() / feature_df.shape[0]\n",
    "  p_ham = feature_df[feature_df.label == 'ham'].label.count() / feature_df.shape[0]\n",
    "  return (p_spam, p_ham)\n",
    "\n",
    "pSpam, pHam = getProbHamSpam(spam, feature_df)\n",
    "print(pSpam, pHam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtoiE24ojPeI",
    "outputId": "3c294bc7-ffab-4158-bae6-ae1fcbb99687"
   },
   "outputs": [],
   "source": [
    "def getSpamWordProbs(feature_df):\n",
    "  ''' \n",
    "  Returns a dictionary of probabilities of 'top' words in messages labeled as spam.\n",
    "  '''\n",
    "  spam_df = feature_df[feature_df.label == 'spam']\n",
    "  spam_word_counts = spam_df[result.keys()].sum(axis=0)\n",
    "  spam_probs = spam_word_counts / spam_df.shape[0]\n",
    "  spam_probs = spam_probs.to_dict()\n",
    "  return spam_probs\n",
    "\n",
    "spam_probs = getSpamWordProbs(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76O8SRd1jnt8",
    "outputId": "63e621d2-7772-42a3-d317-fe4e5bf2b778"
   },
   "outputs": [],
   "source": [
    "def getHamWordProbs(feature_df):\n",
    "  ''' \n",
    "  Returns a dictionary of probabilities of 'top' words in messages labeled as spam.\n",
    "  '''\n",
    "  spam_df = feature_df[feature_df.label == 'ham']\n",
    "  spam_word_counts = spam_df[result.keys()].sum(axis=0)\n",
    "  spam_probs = spam_word_counts / spam_df.shape[0]\n",
    "  spam_probs = spam_probs.to_dict()\n",
    "  return spam_probs\n",
    "\n",
    "ham_probs = getHamWordProbs(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedValues = []\n",
    "wordList = [\"call\", \"free\", \"2\", \"ur\", \"txt\"]\n",
    "indexList = [1, 4, 7, 10, 13]\n",
    "for index, row in test.iterrows():\n",
    "    predictedSpam = pSpam\n",
    "    predictedHam = pHam\n",
    "    for value in range(len(spam_probs)):\n",
    "        index = indexList[value]\n",
    "        word = wordList[value]\n",
    "        vector = row[\"Vectors\"]\n",
    "        if vector[index] == \"1\":\n",
    "            predictedSpam = predictedSpam * spam_probs[word]\n",
    "            predictedHam = predictedHam * ham_probs[word]\n",
    "    if predictedSpam < predictedHam:\n",
    "        template = {\"SpamOrHam\":0}\n",
    "    else:\n",
    "        template = {\"SpamOrHam\":1}\n",
    "    \n",
    "    predictedValues.append(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedValues = pd.DataFrame.from_dict(predictedValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
